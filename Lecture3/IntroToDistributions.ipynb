{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GfRPYAQ7Y5TY"
   },
   "source": [
    "# Introduction to Probability Distributions\n",
    "\n",
    "## Data Science 410\n",
    "\n",
    "This notebook introduces you to the basics of probability distributions. We will start by exploring some common discrete distributions, then explore continuous distributions.\n",
    "\n",
    "Jacob Bernoulli (1654, 1705) was a Swiss mathematician who pioneered many subjects in mathematics, including the mathematical theory of probability. \n",
    "\n",
    "<img src=\"img/Bernoulli.jpg\" alt=\"Drawing\" style=\"width:200px; height:250px\"/>\n",
    "\n",
    "<center>Jacob Bernoulli: Be happy he is not your statistics professor!</center>\n",
    "\n",
    "Bernoulli died before he could publish his book, *Artis conjectandi*. This book included a theory of probabilities from trials with discrete outcomes. His incomplete book was eventually published posthumously in 1713.\n",
    "\n",
    "\n",
    "<img src=\"img/Ars.jpg\" alt=\"Drawing\" style=\"width:200px; height:250px\"/>\n",
    "<center>First probability textbook: How good is your Latin?</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Hj4-ISZwY5TZ"
   },
   "source": [
    "## Discrete Distributions\n",
    "\n",
    "Discrete distributions are used to model the probability of events with discrete outcomes or states. Discrete distributions have a countable number of possible outcomes. The distribution measures the probability of each of these outcomes. We therefore call the distribution function the **Probability Mass Function**.\n",
    "\n",
    "The basic properties of discrete distributions are:\n",
    "\n",
    "- The sum of the probabilities of all possible outcomes (events) must equal 1.\n",
    "- The probability, $p$, of an event is equal to the value of the distribution at that point, and in the range $0 \\le p \\le 1$.\n",
    "- All probabilities are strictly in the range 0-1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JhEaEgo8Y5Ta"
   },
   "source": [
    "### Bernoulli distributions\n",
    "\n",
    "Bernoulli distributions model the results of trial or experiment with a binary outcome. A **Bernoulli trial** is a **single realization**. A classic example of a Bernoulli trial is a single flip of a coin. The flip can only result in two possible outcomes, or end states, $\\{ heads, tails \\}$. \n",
    "\n",
    "For an event with a binary outcome, ${0,1}$ and probability $p$ of state 1, we can write the probability mass function for the Bernoulli distribution as:\n",
    "\n",
    "\\begin{align}\n",
    "P(x\\ |\\ p) &= \\bigg\\{ \n",
    "\\begin{matrix}\n",
    "p\\ if\\ x = 1\\\\\n",
    "(p - 1)\\ if\\ x = 0\n",
    "\\end{matrix}\\\\\n",
    "or\\\\\n",
    "P(x\\ |\\ p) &= p^x(1 - p)^{(1-x)}\\ x \\in {0, 1}\n",
    "\\end{align}\n",
    "\n",
    "Some other basic properties of the Bernoulli distribution are:\n",
    "\n",
    "\\begin{align}\n",
    "Mean &= p\\\\\n",
    "Variance &= p(1-p)\n",
    "\\end{align}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's explore the Bernoulli distribution. The code in the cell below computes the outcome of $1000$ Bernoulli trials with $p = 0.75$. The theoretical and empirical mean and variance for these trials is then displayed. Execute this code and examine the results. How close are the empirical mean and  variance to the theoretical?\n",
    "\n",
    "Execute the code in the cell below to import the required packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "kmNGDpkSZWV8"
   },
   "outputs": [],
   "source": [
    "from __future__ import division \n",
    "\n",
    "import numpy\n",
    "import pandas\n",
    "import scipy\n",
    "import scipy.stats\n",
    "from matplotlib import pyplot\n",
    "import seaborn as sns\n",
    "import seaborn\n",
    "\n",
    "# Configure default plot style.\n",
    "seaborn.set_palette('muted')\n",
    "seaborn.set_style('ticks')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code in the cell below computes 1000 realizations of Bernoulli trials. The the first argument of [numpy.random.binomial](https://docs.scipy.org/doc/numpy-1.14.0/reference/generated/numpy.random.binomial.html) is the number of realization from a trial. Setting this argument to 1 creates a Bernoulli trial. Execute the code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 35,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 378,
     "status": "ok",
     "timestamp": 1512611088527,
     "user": {
      "displayName": "Drew Bryant",
      "photoUrl": "//lh4.googleusercontent.com/-bbwiO20N-0M/AAAAAAAAAAI/AAAAAAAAAJg/qqZ1Ilm078o/s50-c-k-no/photo.jpg",
      "userId": "111241008704641611320"
     },
     "user_tz": 480
    },
    "id": "4WRHHclxZH-Y",
    "outputId": "33fd86c9-ceaa-4d53-be70-00aa2f350a08"
   },
   "outputs": [],
   "source": [
    "# Bernoulli (Binomial with n = 1)\n",
    "p = 0.75\n",
    "n = 1000\n",
    "\n",
    "# Compute `n` random draws\n",
    "bern_samples = numpy.random.binomial(1, p, n)\n",
    "bern_samples.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code in the cell below computes and displays the theoretical mean of the distribution and empirical mean of sample. Execute this code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 35,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 391,
     "status": "ok",
     "timestamp": 1512611089020,
     "user": {
      "displayName": "Drew Bryant",
      "photoUrl": "//lh4.googleusercontent.com/-bbwiO20N-0M/AAAAAAAAAAI/AAAAAAAAAJg/qqZ1Ilm078o/s50-c-k-no/photo.jpg",
      "userId": "111241008704641611320"
     },
     "user_tz": 480
    },
    "id": "KYSn_8C9ZmHs",
    "outputId": "81953cf8-eaaa-4acc-af21-9a034f0e63fd"
   },
   "outputs": [],
   "source": [
    "bern_sample_mean = bern_samples.sum() / bern_samples.size\n",
    "# Note: there's also a built-in for mean: `bern_samples.mean()`\n",
    "\n",
    "# The expected mean is `p`\n",
    "print('p = %.3f    Sample mean = %.3f' % (p, bern_sample_mean))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the theoretical and empirical means are quite close.  \n",
    "\n",
    "Next, execute the code in the cell below to display the theoretical variance and the empirical variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 35,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 397,
     "status": "ok",
     "timestamp": 1512611089514,
     "user": {
      "displayName": "Drew Bryant",
      "photoUrl": "//lh4.googleusercontent.com/-bbwiO20N-0M/AAAAAAAAAAI/AAAAAAAAAJg/qqZ1Ilm078o/s50-c-k-no/photo.jpg",
      "userId": "111241008704641611320"
     },
     "user_tz": 480
    },
    "id": "74OXSPiUaCkA",
    "outputId": "62d0fdd1-a404-4868-c497-7e2bb480edbc"
   },
   "outputs": [],
   "source": [
    "# Compute the variance of the samples\n",
    "bern_sample_var = bern_sample_mean * (1 - bern_sample_mean)\n",
    "# Note: there's also a built-in for variance: `bern_samples.var()`\n",
    "\n",
    "# Compute the expected variance\n",
    "bern_var = p * (1 - p)\n",
    "\n",
    "print('Bernoulli variance = %.3f   Sample variance = %.3f' % (bern_var, bern_sample_var))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, the theoretical variance and the empirical sample variance are again reasonably close. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZPvuKzTHY5Tg"
   },
   "source": [
    "**Your turn:** With $p = 0.75$ we expect that 75% of the trials with end with a value of 1. Verify this expectation by plotting a simple histogram of the variable `bern_samples` you just computed. Note that the code in the cell allows you to size the figure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 246,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 518,
     "status": "ok",
     "timestamp": 1512612171940,
     "user": {
      "displayName": "Drew Bryant",
      "photoUrl": "//lh4.googleusercontent.com/-bbwiO20N-0M/AAAAAAAAAAI/AAAAAAAAAJg/qqZ1Ilm078o/s50-c-k-no/photo.jpg",
      "userId": "111241008704641611320"
     },
     "user_tz": 480
    },
    "id": "2U22m7YVbX8P",
    "outputId": "0ccba2bb-71ff-427a-e325-02981c512375"
   },
   "outputs": [],
   "source": [
    "pyplot.hist(bern_samples, bins = 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UmsIcWTYY5Tp"
   },
   "source": [
    "### Binomial distribution\n",
    "\n",
    "We have just computed the outcome of a number of independent Bernoulli trials. The product of **multiple Bernoulli trials is a Binomial distribution**. For example, if we perform a number of Bernoulli trials ($\\{success, fail \\}$) on a sample (with replacement) of a population the number of successes will be a binomial distribution. \n",
    "\n",
    "The probability of $N$ Bernoulli trials with probability of positive outcome $p$ is written as:\n",
    "\n",
    "$$P(x\\ |\\ N, p) = \\binom{N}{x} p^x(1 - p)^{(N-x)}$$\n",
    "\n",
    "Notice that the product includes the term $\\binom{N}{x}$ since we must account for all possible combinations of outcomes from the trials. \n",
    "\n",
    "The mean and variance are just the Bernoulli mean and variance multiplied by the number or trials:\n",
    "\n",
    "\\begin{align}\n",
    "Mean &= n p\\\\\n",
    "Variance &= n p(1-p)\n",
    "\\end{align}\n",
    "\n",
    "\n",
    "Let's try computing several Binomial distributions, with probability of success $p = 0.75$, and $N = \\{5, 25, 75 \\}$. The code in the cell below computes $1000$ realizations of the Binomial distribution for each value of $N$. The theoretical and sample means and variances are computed and printed for each case. Execute this code and examine the results. Are the sample means and variances close to the theoretical values?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 142,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 339,
     "status": "ok",
     "timestamp": 1512612158038,
     "user": {
      "displayName": "Drew Bryant",
      "photoUrl": "//lh4.googleusercontent.com/-bbwiO20N-0M/AAAAAAAAAAI/AAAAAAAAAJg/qqZ1Ilm078o/s50-c-k-no/photo.jpg",
      "userId": "111241008704641611320"
     },
     "user_tz": 480
    },
    "id": "1KDqzuMJbzr3",
    "outputId": "5a5b880e-130a-401d-bf86-ed2019df8d16"
   },
   "outputs": [],
   "source": [
    "# Binomial sampling\n",
    "trials = numpy.array([5, 25, 75])\n",
    "binom_samples = [numpy.random.binomial(t, p, n) for t in trials]\n",
    "\n",
    "binom_sample_means = [samples.mean() for samples in binom_samples]\n",
    "binom_means = trials * p\n",
    "pandas.DataFrame({\n",
    "    'Trials': trials,\n",
    "    'BinomialMean': binom_means,\n",
    "    'SampleMean': binom_sample_means,\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, the theoretical mean and sample mean are quite similar for each sample size.  \n",
    "\n",
    "Execute the code in the cells below to compute and display the theoretical and empirical variance for the samples.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 142,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 547,
     "status": "ok",
     "timestamp": 1512612160217,
     "user": {
      "displayName": "Drew Bryant",
      "photoUrl": "//lh4.googleusercontent.com/-bbwiO20N-0M/AAAAAAAAAAI/AAAAAAAAAJg/qqZ1Ilm078o/s50-c-k-no/photo.jpg",
      "userId": "111241008704641611320"
     },
     "user_tz": 480
    },
    "id": "cnU1e9RodtSW",
    "outputId": "05091e65-8aef-4033-dc3a-269d222c9d83"
   },
   "outputs": [],
   "source": [
    "binom_sample_vars = [samples.var() for samples in binom_samples]\n",
    "binom_vars = trials * p * (1 - p)\n",
    "pandas.DataFrame({\n",
    "    'Trials': trials,\n",
    "    'BinomialVariance': binom_vars,\n",
    "    'SampleVariance': binom_sample_vars\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZXPrs3hHY5Ts"
   },
   "source": [
    "**Your turn:** In the cell below, create and execute the coded to plot the simple histograms of the three Binomial distributions in the `binom_samples` list. Do these distributions appear as you expect? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "pWGORoADY5Tt"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fKLHwTV2Y5Tw"
   },
   "source": [
    "Notice that while the outcome of each Bernoulli trial is a discrete binary result, the product of multiple trials can take many discrete values. In fact, as $N$ becomes large the Binomial distribution starts to look like a continuous distribution. In fact, the Binomial distribution converges to the continuous Normal distribution as $N \\rightarrow \\infty$. \n",
    "\n",
    "The code in the cell below computes the histogram of of the Binomial distribution and then the density of the equivelent Normal distribution. This done for the three sets of mean and variance previously computed with probability of success $p = 0.75$, and $N = \\{5, 25, 75 \\}$. Execute this code and examine the results. How does the Binomial distributon converge to the Normal distribution as $N$ increases?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 277,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 695,
     "status": "ok",
     "timestamp": 1512612162324,
     "user": {
      "displayName": "Drew Bryant",
      "photoUrl": "//lh4.googleusercontent.com/-bbwiO20N-0M/AAAAAAAAAAI/AAAAAAAAAJg/qqZ1Ilm078o/s50-c-k-no/photo.jpg",
      "userId": "111241008704641611320"
     },
     "user_tz": 480
    },
    "id": "hPGNVfQ2f_kX",
    "outputId": "5f11fbbf-f856-4569-f2cb-651a15c3c6b9"
   },
   "outputs": [],
   "source": [
    "for i in range(len(trials)):\n",
    "    pyplot.subplot(len(trials), 1, i+1) # Create one plot per row (one for each trial)\n",
    "    resolution = 1000  # How many points to sample from the PDF of the normal distribution\n",
    "    x_norm = numpy.linspace(0, trials[i], resolution)\n",
    "    y_norm = scipy.stats.norm.pdf(\n",
    "        x_norm, # Where we want to evaluate the PDF\n",
    "        loc=binom_means[i], # The mean of the distribution\n",
    "        scale=numpy.sqrt(binom_vars[i])) # The std deviation of the distribution\n",
    "\n",
    "    # Plot the samples\n",
    "    sns.distplot(binom_samples[i], kde_kws={'bw':1.0})\n",
    "    # Plot the normal distribution PDF\n",
    "    pyplot.plot(x_norm, y_norm, color='red')\n",
    "    pyplot.xlim(0, trials[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mvsxIOypY5T0"
   },
   "source": [
    "### Poisson distribution\n",
    "\n",
    "A common problem is modeling the counts of events occurring within a period of time. The Poisson distribution models the occurrence of events in a fixed interval of time. We say that the Poisson distribution models the probability, $P$, of x **arrivals** within the time period. \n",
    "\n",
    "In mathematical terms we write the Poisson distribution in terms of the average arrival rate, $\\lambda$ as:\n",
    "\n",
    "$$ \n",
    "P(x\\ |\\ \\lambda) = \\frac{\\lambda^x}{x!} \\exp^{-\\lambda}\n",
    "$$\n",
    "\n",
    "The mean and variance of the Poisson distribution are both equal to the parameter $\\lambda$, or:\n",
    "\n",
    "\\begin{align}\n",
    "Mean = \\lambda\\\\\n",
    "Variance = \\lambda\n",
    "\\end{align}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code in the cell below computes $1000$ realizations of Poisson distributions with average arrival rates, $\\lambda = \\{ 1, 5, 25, 100\\}$. The sample mean and variance for each distribution is then computed and printed along with the theoretical values. Execute this code and examine the results. Do the theoretical values agree with the sample estimates? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 173,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 308,
     "status": "ok",
     "timestamp": 1512612115432,
     "user": {
      "displayName": "Drew Bryant",
      "photoUrl": "//lh4.googleusercontent.com/-bbwiO20N-0M/AAAAAAAAAAI/AAAAAAAAAJg/qqZ1Ilm078o/s50-c-k-no/photo.jpg",
      "userId": "111241008704641611320"
     },
     "user_tz": 480
    },
    "id": "JwZnSrjRlHV_",
    "outputId": "86fe4baf-5f10-438a-8d63-44057ff72107"
   },
   "outputs": [],
   "source": [
    "lambdas = [1, 5, 25, 100]\n",
    "poisson_samples = [numpy.random.poisson(l, n) for l in lambdas]\n",
    "\n",
    "poisson_sample_means = [samples.mean() for samples in poisson_samples]\n",
    "poisson_sample_vars = [samples.var() for samples in poisson_samples]\n",
    "\n",
    "pandas.DataFrame({\n",
    "    'PoissonMean': lambdas,\n",
    "    'SampleMean': poisson_sample_means,\n",
    "    'SampleVar': poisson_sample_vars,\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jWJfL4MmY5T5"
   },
   "source": [
    "As with the Binomial distribution, you can see that as $\\lambda$ the discrete Poisson distribution approaches continuous Normal distribution. The code in the cell below plots histograms of the Poisson distribution along with the density of the equivalent Normal distributions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 504,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1009,
     "status": "ok",
     "timestamp": 1512612116692,
     "user": {
      "displayName": "Drew Bryant",
      "photoUrl": "//lh4.googleusercontent.com/-bbwiO20N-0M/AAAAAAAAAAI/AAAAAAAAAJg/qqZ1Ilm078o/s50-c-k-no/photo.jpg",
      "userId": "111241008704641611320"
     },
     "user_tz": 480
    },
    "id": "vZ5yoUmOp5yp",
    "outputId": "eb69edfa-420b-4777-e19f-b48dc6969b92"
   },
   "outputs": [],
   "source": [
    "nrows = 2\n",
    "pyplot.figure(figsize=(8, 8))\n",
    "\n",
    "for i in range(len(lambdas)):\n",
    "    pyplot.subplot(len(lambdas) / nrows, nrows, i+1, \n",
    "                   title='lambda = %d' % lambdas[i])\n",
    "\n",
    "    x_norm = numpy.linspace(0, 5*lambdas[i], resolution)\n",
    "    y_norm = scipy.stats.norm.pdf(\n",
    "        x_norm, # Where we want to evaluate the PDF\n",
    "        loc=lambdas[i], # The mean of the distribution\n",
    "        scale=numpy.sqrt(lambdas[i])) # The std deviation of the distribution\n",
    "\n",
    "    # Plot the samples\n",
    "    sns.distplot(poisson_samples[i], kde_kws={'bw':1.0})\n",
    "    # Plot the normal distribution PDF\n",
    "    pyplot.plot(x_norm, y_norm, color='red')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JTtPYPQRY5T9"
   },
   "source": [
    "## Continuous Distributions\n",
    "\n",
    "Continuous distributions are used to model variables with continuous valued random variables. Physical measurements, such as weight, length and temperature, are examples of variables with continuous variables. \n",
    "\n",
    "Continuous distributions have an infinite number of possible outcomes. The distribution measures the probability for some range of values. We therefore call the distribution function the **Probability Density Function**. This is in contrast to the probability mass function for discrete distributions. \n",
    "\n",
    "Properties of continuous probability density functions are:\n",
    "\n",
    "- The area under the distribution curve must be equal to 1, integrated over the range of possible values:   \n",
    "\n",
    "$$\\int_{-\\infty}^{\\infty} P(x) dx = 1$$    \n",
    "\n",
    "- The probability of a range of values of an event equals the **area** under density curve over that range of values, $\\{X_1, X_2\\}$ is:    \n",
    "\n",
    "$$P({X_1, X_2}) = \\int_{X_1}^{X_2} P(x) dx $$\n",
    "\n",
    "- Probabilities must be bounded by 0 and 1:\n",
    "\n",
    "$$0 \\le \\int_{X_1}^{X_2} P(x) dx \\le 1$$\n",
    "\n",
    "- The probability of any single, exact value, is 0:\n",
    "\n",
    "$$\\int_{X_1}^{X_1} P(x) dx = 0$$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Q_NlSORXY5T9"
   },
   "source": [
    "### Uniform distribution\n",
    "\n",
    "A Uniform distribution has flat probability between limits $\\{ a, b \\}$ and $0$ outside that interval. The Uniform distribution is used in a number of applications, including random selection of data and in simulation. Further, transformations of the Uniform distribution are typically used to generate realizations of other distributions. \n",
    "\n",
    "We can write the probability of the the Uniform distribution as:\n",
    "\n",
    "$$\n",
    "P(x\\ | \\{a,b \\}) = \\Bigg\\{ \n",
    "\\begin{matrix}\n",
    "\\frac{1}{(b - a)}\\ if\\ a \\le x \\le b\\\\\n",
    "0\\ if\\ x \\lt a\\ or\\ x\\ \\gt b\n",
    "\\end{matrix}\n",
    "$$\n",
    "\n",
    "The Uniform distribution has the following \n",
    "\n",
    "\\begin{align}\n",
    "Mean &= \\frac{(a + b)}{2}\\\\\n",
    "Variance &= \\frac{1}{2}(b - a)^2\n",
    "\\end{align}\n",
    "\n",
    "The code in the cell below computes and plots the uniform distribution on the interval $\\{ 0, 1 \\}$, along with the kernel density plot. Execute this code and  examine the result. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 286,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 358,
     "status": "ok",
     "timestamp": 1512612117088,
     "user": {
      "displayName": "Drew Bryant",
      "photoUrl": "//lh4.googleusercontent.com/-bbwiO20N-0M/AAAAAAAAAAI/AAAAAAAAAJg/qqZ1Ilm078o/s50-c-k-no/photo.jpg",
      "userId": "111241008704641611320"
     },
     "user_tz": 480
    },
    "id": "rOvCLFvavkfC",
    "outputId": "0a136ea9-6485-4671-ca38-995de0b8d10b"
   },
   "outputs": [],
   "source": [
    "numpy.random.seed(876)\n",
    "uniform_samples = numpy.random.uniform(0, 1, n)\n",
    "\n",
    "# Plot the distribution of samples\n",
    "seaborn.kdeplot(uniform_samples, color='black')\n",
    "\n",
    "# Draw the uniform PDF\n",
    "pyplot.vlines(0, 0, 1, colors='red')\n",
    "pyplot.hlines(1, 0, 1, colors='red')\n",
    "pyplot.vlines(1, 0, 1, colors='red')\n",
    "_ = pyplot.title('Density of Uniform distribution')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FwUEVgqnY5UA"
   },
   "source": [
    "Let's try simulating some Uniform distributions. The code in the cell below creates and plots the histogram Uniform distributions with $\\{100, 1000, 10000, 100000\\}$ realizations, along with the theoretical density. Execute this code and examine the results. Notice how close each histogram is to the theoretical density. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 504,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 859,
     "status": "ok",
     "timestamp": 1512612118176,
     "user": {
      "displayName": "Drew Bryant",
      "photoUrl": "//lh4.googleusercontent.com/-bbwiO20N-0M/AAAAAAAAAAI/AAAAAAAAAJg/qqZ1Ilm078o/s50-c-k-no/photo.jpg",
      "userId": "111241008704641611320"
     },
     "user_tz": 480
    },
    "id": "ZAO9u-FCwyGB",
    "outputId": "09fd6ed5-b2a6-4123-b430-aff15cfe27af"
   },
   "outputs": [],
   "source": [
    "trials = [100, 1000, 10000, 100000]\n",
    "\n",
    "nrows = 2\n",
    "pyplot.figure(figsize=(8, 8))\n",
    "nbins = 10  # how many bins to use for each histogram\n",
    "for i in range(len(trials)):\n",
    "  pyplot.subplot(\n",
    "      len(trials) / nrows, nrows, i+1, \n",
    "      title='# samples = %d' % trials[i]) \n",
    "\n",
    "  h = trials[i] / nbins\n",
    "  pyplot.vlines(0, 0, h, colors='red')\n",
    "  pyplot.hlines(h, 0, 1, colors='red')\n",
    "  pyplot.vlines(1, 0, h, colors='red')  \n",
    "  \n",
    "  # Plot the samples\n",
    "  pyplot.hist(numpy.random.uniform(0, 1, trials[i]), \n",
    "              bins=nbins, color='white', edgecolor='black')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "e7_wi9qEY5UE"
   },
   "source": [
    "\n",
    "### Normal distribution\n",
    "\n",
    "The Normal distribution is one of the most widely used probability distributions. Any case where values are the result of product of a large number of processes will converge to a Normal distribution. Many physical processes produce measurement values which are well modeled by a Normal distribution or Log-Normal distribution.\n",
    "\n",
    "For a Normal distribution we can write the density function as:\n",
    "\n",
    "$$P(x) = \\frac{1}{\\sqrt{2 \\pi \\sigma^2}} \\exp{\\frac{-(x - \\mu)^2}{2 \\sigma^2}}$$\n",
    "\n",
    "The parameters can be interpreted as:\n",
    "\n",
    "\\begin{align}   \n",
    "\\mu &= location\\ parameter = mean \\\\\n",
    "\\sigma &= scale = standard\\ deviation \\\\\n",
    "\\sigma^2 &= Variance \n",
    "\\end{align}\n",
    "\n",
    "\n",
    "In other words, the location parameter sets the center of the distribution. The scale determines spread or width of the distribution.\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code in the cell below computes and plots the Normal distribution for four different combinations of location and scale, as shown in the table:\n",
    "\n",
    "| $\\mu$ | $\\sigma$ |\n",
    "|:-----:|:-------:|\n",
    "| 0     | 1       |\n",
    "| 5     | 1       |\n",
    "| 0     | 0.1     |\n",
    "| 4     | 4       |\n",
    "\n",
    "Execute this code and examine the results. Notice how the center of the distribution changes with the location and the width of the distribution changes with the scale.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 286,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 557,
     "status": "ok",
     "timestamp": 1512612118755,
     "user": {
      "displayName": "Drew Bryant",
      "photoUrl": "//lh4.googleusercontent.com/-bbwiO20N-0M/AAAAAAAAAAI/AAAAAAAAAJg/qqZ1Ilm078o/s50-c-k-no/photo.jpg",
      "userId": "111241008704641611320"
     },
     "user_tz": 480
    },
    "id": "LKWZ8MW9yvQR",
    "outputId": "0fb7cd3c-4f7f-4163-9038-545c45560edd"
   },
   "outputs": [],
   "source": [
    "n = 100000\n",
    "\n",
    "norm_params = [\n",
    "    # (mean, var)\n",
    "    (0, 1),\n",
    "    (5, 1),\n",
    "    (0, .1),\n",
    "    (4, 4)\n",
    "]\n",
    "\n",
    "norm_samples = [numpy.random.normal(mean, numpy.sqrt(var), n)\n",
    "                for mean, var in norm_params]\n",
    "\n",
    "pyplot.title('Plot of normals')\n",
    "colors = ('black', 'red', 'blue', 'green')\n",
    "for i, samples in enumerate(norm_samples):\n",
    "  seaborn.kdeplot(samples, color=colors[i], \n",
    "                  label='N(%.1f, %.1f)' % norm_params[i])\n",
    "pyplot.xlim(-3, 9)\n",
    "_ = pyplot.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FA1Ky1DyY5UH"
   },
   "source": [
    "We have now explored the basic properties of the Normal distribution. The relationship between the the quantiles and the number of standard deviations, $\\sigma$, to the left or right of center is another important property of the Normal distribution. An understanding of this relationship provides some intuition about the likelihood of events under the Normal distribution.\n",
    "\n",
    "The code in the cell below plots a histogram of 100000 realizations of a **standard Normal distribution** ($\\mu = 0.0,\\ \\sigma = 1$). Vertical lines are plotted at $\\sigma = \\{-3, -2, -1,\\ 0,\\ 1,\\ 2,\\ 3\\}$. Execute this code and examine the results. Notice that events become quite unlikely as $\\sigma$ becomes large."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 304,
     "output_extras": [
      {
       "item_id": 1
      },
      {
       "item_id": 2
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 725,
     "status": "ok",
     "timestamp": 1512612119699,
     "user": {
      "displayName": "Drew Bryant",
      "photoUrl": "//lh4.googleusercontent.com/-bbwiO20N-0M/AAAAAAAAAAI/AAAAAAAAAJg/qqZ1Ilm078o/s50-c-k-no/photo.jpg",
      "userId": "111241008704641611320"
     },
     "user_tz": 480
    },
    "id": "qB1suO2L2-OU",
    "outputId": "ae6220f7-4e69-4317-b6b2-57b6f04fbb63"
   },
   "outputs": [],
   "source": [
    "n = 100000\n",
    "\n",
    "std_norm_samples = numpy.random.standard_normal(n)\n",
    "\n",
    "pyplot.title('Histogram of std Normal')\n",
    "pyplot.hist(std_norm_samples, bins=61, color='white', edgecolor='black')\n",
    "# Draw lines at each standard deviation from the mean\n",
    "pyplot.vlines(range(-3, 4), 0, 6000, color='red')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What are **cumulative probability** at each of the points showing in the above chart? The code in the cell below uses the [scipy.stats.norm.cdf](https://docs.scipy.org/doc/scipy-0.16.0/reference/generated/scipy.stats.norm.html) function to compute these probabilities. Execute this code and examine the results.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 266,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 317,
     "status": "ok",
     "timestamp": 1512612120314,
     "user": {
      "displayName": "Drew Bryant",
      "photoUrl": "//lh4.googleusercontent.com/-bbwiO20N-0M/AAAAAAAAAAI/AAAAAAAAAJg/qqZ1Ilm078o/s50-c-k-no/photo.jpg",
      "userId": "111241008704641611320"
     },
     "user_tz": 480
    },
    "id": "QSa9dpkLFjk3",
    "outputId": "6114b96d-a167-4d8a-b639-8bcd28e12deb"
   },
   "outputs": [],
   "source": [
    "std_thresholds = range(-3, 4)\n",
    "quantiles = scipy.stats.norm.cdf(std_thresholds, scale=1, loc=0)\n",
    "pandas.DataFrame({\n",
    "    'std deviations': std_thresholds,\n",
    "    'quantile': quantiles,\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The probability of an event occurring outside the range of $+/- 3$ standard deviations is less than 0.3%. And the probability of an event outside the range of $+/- 2$ standard deviations is about 5%. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The density function of the Normal distribution has the famous **bell-shaped curve**. But, how does this shape arise as the number of samples increases? Execute the code in the cell below to find out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 504,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1733,
     "status": "ok",
     "timestamp": 1512612122265,
     "user": {
      "displayName": "Drew Bryant",
      "photoUrl": "//lh4.googleusercontent.com/-bbwiO20N-0M/AAAAAAAAAAI/AAAAAAAAAJg/qqZ1Ilm078o/s50-c-k-no/photo.jpg",
      "userId": "111241008704641611320"
     },
     "user_tz": 480
    },
    "id": "H7YfCIeFAi6O",
    "outputId": "018035fb-97ad-4cc3-8bd2-dd9fb3147d57"
   },
   "outputs": [],
   "source": [
    "pyplot.figure(figsize=(8, 8))\n",
    "\n",
    "for i, n in enumerate([100, 1000, 10000, 100000]):\n",
    "    std_norm_samples = numpy.random.standard_normal(n)\n",
    "    title = 'n = %d, sample mean = %.3f' % (n, std_norm_samples.mean())\n",
    "    pyplot.subplot(2, 2, i+1, title=title) \n",
    "    sns.distplot(std_norm_samples, bins=30, kde_kws={'bw':0.4})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The lesson here is that for smaller samples events generated by a Normal distribution process can appear to deviate significantly from the ideal density curve. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "t9g3_E-MY5UQ"
   },
   "source": [
    "### Log-Normal distribution\n",
    "\n",
    "The Normal distribution is defined for continuous random variables in the range $-\\infty \\le x \\le \\infty$. However, many quantities are only defined in a range $0 \\lt x \\le \\infty$. Examples include, price, weight, length, and volume. In many of these cases the **Log-Normal** distribution is a good choice for the data generating process.  \n",
    "\n",
    "The Log-Normal distribution is based on a log-transformation of the random variable. The probability density function is:  \n",
    "\n",
    "$$P(x) = \\frac{1}{x} \\frac{1}{\\sigma \\sqrt{2 \\pi}} \\exp{\\frac{-(log(x) - \\mu)^2}{2 \\sigma^2}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code in the cell below computes and plots 100,000 realizations of a standard Log-Normal distribution using the [scipy.stats.lognorm.pdf](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.lognorm.html) function. The standard Log-Normal distribution has location = 0 and scale = 1. Execute the code in the cell below and examine the result.       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 304,
     "output_extras": [
      {
       "item_id": 1
      },
      {
       "item_id": 2
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 631,
     "status": "ok",
     "timestamp": 1512612122947,
     "user": {
      "displayName": "Drew Bryant",
      "photoUrl": "//lh4.googleusercontent.com/-bbwiO20N-0M/AAAAAAAAAAI/AAAAAAAAAJg/qqZ1Ilm078o/s50-c-k-no/photo.jpg",
      "userId": "111241008704641611320"
     },
     "user_tz": 480
    },
    "id": "Ugc0H62UBURv",
    "outputId": "35c61fb4-ab62-4b93-aa48-30546752d976"
   },
   "outputs": [],
   "source": [
    "x = numpy.linspace(.01, 10, num=100000)\n",
    "log_normal_pdf = scipy.stats.lognorm.pdf(x, 1)\n",
    "pyplot.plot(x, log_normal_pdf)\n",
    "pyplot.title('Density of std Log-Normal')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8PD2DGyVY5US"
   },
   "source": [
    "**Your turn:** The Log-Normal distribution is on log scale. You can transform the Log-Normal distribution to a Normal distribution. In the cell below create and excute the code to natural log transform the x variable and plot the density. How does this result compair to a standard Normal distribution.      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 295,
     "output_extras": [
      {
       "item_id": 1
      },
      {
       "item_id": 2
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 762,
     "status": "ok",
     "timestamp": 1512612123808,
     "user": {
      "displayName": "Drew Bryant",
      "photoUrl": "//lh4.googleusercontent.com/-bbwiO20N-0M/AAAAAAAAAAI/AAAAAAAAAJg/qqZ1Ilm078o/s50-c-k-no/photo.jpg",
      "userId": "111241008704641611320"
     },
     "user_tz": 480
    },
    "id": "j6oYNZaJCscE",
    "outputId": "1a05c2e3-39f2-4c6c-c5db-c456f950ae6b"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Arkk3Jh5Y5UV"
   },
   "source": [
    "### Student t-distribution\n",
    "\n",
    "The [Student t-distribution](https://en.wikipedia.org/wiki/Student%27s_t-distribution), often just referred to as the t-distribution. This distribution is of importance in statistics since the difference of the means of two Normally distributed random variables is t-distributed. This property makes the t-distribution important in hypothesis testing.  \n",
    "\n",
    "The t-distribution is defined in a somewhat different way from the other distributions we have looked at. It has one parameter, the **degrees of freedom**, denoted as $\\nu$. The derivation of the density function for the t-distribution is a bit complicated and leads to the following, rather complex result:\n",
    "\n",
    "$$\n",
    "P(x\\ |\\ \\nu) = \\frac{\\Gamma(\\frac{\\nu + 1}{2})}{\\sqrt{\\nu \\pi} \\Gamma(\\frac{\\nu}{2})} \\bigg(1 + \\frac{x^2}{\\nu} \\bigg)^{- \\frac{\\nu + 1}{2}}\\\\\n",
    "where\\\\\n",
    "\\Gamma(x) = Gamma\\ function\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Despite the complex density formula, you can gain a fair feel for the behavior of the t-distribution by plotting it for several values of the degrees of freedom, $\\nu$, and comparing it to the Normal distribution. The code in the cell below plots the density function for the t-distribution for degrees of freedom, $\\nu = \\{1, 2, 3, \\infty \\}$, along with a standard Normal distribution. Execute this code and examine the results. Notice how the t-distribution is wider with heavier tails than the Normal distribution for low degrees of freedom. As $\\nu \\rightarrow \\infty$ the t-distribution becomes identical to the Normal distribution. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 277,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 611,
     "status": "ok",
     "timestamp": 1512612124445,
     "user": {
      "displayName": "Drew Bryant",
      "photoUrl": "//lh4.googleusercontent.com/-bbwiO20N-0M/AAAAAAAAAAI/AAAAAAAAAJg/qqZ1Ilm078o/s50-c-k-no/photo.jpg",
      "userId": "111241008704641611320"
     },
     "user_tz": 480
    },
    "id": "XbmfKZgEEQTn",
    "outputId": "2305569f-28ee-46c9-c198-79e616f28625"
   },
   "outputs": [],
   "source": [
    "x = numpy.linspace(-4, 4, num=100)\n",
    "\n",
    "# Plot the normal distribution PDF\n",
    "pyplot.plot(x, scipy.stats.norm.pdf(x), color='black', linewidth=4, label='N(0,1)')\n",
    "\n",
    "for df, color in zip([1, 2, 5, 1000], ['red', 'blue', 'green', 'orange']):  \n",
    "  pyplot.plot(x, scipy.stats.t.pdf(x, df), label='t(%d)' % df, color=color)\n",
    "_ = pyplot.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JDv5mJs0Y5UY"
   },
   "source": [
    "### Gamma and Exponential distributions\n",
    "\n",
    "The Gamma distributions are a complex family of continuous probability distributions. All distributions in the Gamma family are only defined for $0 \\ge x \\ge \\infty$.\n",
    "\n",
    "We will look at one special cases of particular interest, the **exponential distribution**. The Exponential distribution is used to model waiting times between events and events where the probability density decays with time. We can write the probability density function of the Exponential distribution as:\n",
    "\n",
    "$$P(x; \\lambda) = \\bigg\\{ \n",
    "\\begin{matrix}\n",
    "\\lambda \\exp^{- \\lambda x}\\ if\\ x \\ge 0\\\\\n",
    "0\\ if\\ x \\lt 0\n",
    "\\end{matrix}\\\\\n",
    "\\\\\n",
    "where\\\\\n",
    "Average\\ arrival\\ rate\\ = Expected\\ value\\ = E[X] = \\frac{1}{\\lambda}\\\\\n",
    "Var[X] = \\frac{1}{\\lambda^2}\n",
    "$$\n",
    "\n",
    "Notice also that:\n",
    "\n",
    "$$average\\ time\\ between\\ events = \\lambda = \\frac{1}{average\\ arrival\\ rate}$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get a feel for the Exponential distribution, let's plot it for arrival rates of $\\{0.5, 1.0, 2.0  \\}$ or $\\lambda = \\{ 2.0, 1.0, 0.5 \\}$. Execute the code in the cell below to create the plot. Notice how the density function changes with $\\lambda$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 286,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 685,
     "status": "ok",
     "timestamp": 1512612125255,
     "user": {
      "displayName": "Drew Bryant",
      "photoUrl": "//lh4.googleusercontent.com/-bbwiO20N-0M/AAAAAAAAAAI/AAAAAAAAAJg/qqZ1Ilm078o/s50-c-k-no/photo.jpg",
      "userId": "111241008704641611320"
     },
     "user_tz": 480
    },
    "id": "kXYe5ofDHrMO",
    "outputId": "35e242ab-39fd-4ae2-f306-e1586d976514"
   },
   "outputs": [],
   "source": [
    "x = numpy.linspace(0, 5, num=100)\n",
    "lambdas = [.5, 1., 2.]\n",
    "colors = ['red', 'blue', 'green']\n",
    "\n",
    "for i in range(len(lambdas)):\n",
    "  pyplot.plot(x, scipy.stats.expon.pdf(\n",
    "      x, loc=0, scale=1/lambdas[i]), color=colors[i], label=lambdas[i])\n",
    "  \n",
    "pyplot.legend()\n",
    "_ = pyplot.title('Density of Exponential distribution')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GGpgt08qY5Ub"
   },
   "source": [
    "## Exponential Distributions\n",
    "\n",
    "You may have noticed that several of the distributions we have discussed use exponential functions to compute the probabilities. We call this family of probability distributions the **exponential family**.   \n",
    "\n",
    "Exponential family distributions have tractable mathematical properties. Understanding of one distribution helps understand the others.   \n",
    "\n",
    "Further, exponential distributions are widely useful. They show up in physical problems as well as many data problems.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ok973LYTY5Uc"
   },
   "source": [
    "## Summary\n",
    "\n",
    "In this notebook you have explored the properties of certain discrete and continuous probability distributions. We can summmarize the properties of these distributions as follows:\n",
    "\n",
    "1. Discrete distributions\n",
    " - Discrete distributions are used to model the probability of events with discrete outcomes or states. \n",
    " - We call the distribution function the **Probability Mass Function**.\n",
    " - The sum of the probabilities of all possible events must equal 1.\n",
    " - The probability of an event is equal to the value of the distribution at that point.\n",
    " - All probabilities are strictly in the range 0-1.\n",
    "2. Continuous distributions\n",
    " - Continuous distributions have an infinite number of possible outcomes. The distribution measures the probability for some range of values. \n",
    " - We call the distribution function the **Probability Density Function**. \n",
    " - The probability of a range of values of an event equals the **area** under density curve over that range of values.\n",
    " - Probabilities cannot have negative values.\n",
    " - The probability of any single, exact value, is 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "ENaI7DKxY5Ud"
   },
   "source": [
    "#### Copyright 2019, 2020, Stephen F Elston. All rights reserved. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "default_view": {},
   "name": "IntroToDistributions.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
