{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Tests for Categorical Data\n",
    "\n",
    "\n",
    "### Data Science 410\n",
    "\n",
    "\n",
    "## Introduction to Tests for Categorical Data\n",
    "\n",
    "So far, we have been investigating tests for data with continious values. But, many data types are categorical where we work with count statistics. Which hypothesis tests can we apply to these?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Pearson's Chi-Squared Test\n",
    "\n",
    "One of the earliest tests for count data was developed by Karl Pearson around 1900. Despite its age, this test is still used today. The Pearson Chi-squared test (also written as $\\chi$-squared) has the following properties:\n",
    "\n",
    "- $\\chi$-squared is an unpaired test for counts in different categories.\n",
    "  * Tests if different categories result in significantly different counts.\n",
    "  * These categories must be mutually exclusive. For example, does the patient have cancer? (yes/no)\n",
    "- Examples of test on counts.\n",
    "  * Rolling a die. Do the six categories, (1,2,3,4,5,6), occur the same frequency (fair die)?\n",
    "  * Do a group of tweets contain a specific word with unexpectedly high or low frequency?\n",
    "  * test if the two categories differ in tweet length or word count.\n",
    "- The Chi-squared statistic depends on the **degrees of freedom** of the test.\n",
    "  * This is equal to n-1.  Where n equals the number of different categories.\n",
    "- The test uses the sum of the differences of outcomes from expectations.\n",
    "- Chi-squared is also used as a **goodness of fit** test. That is to test if sample is representative of population.\n",
    "  - Test if your sample has expected make up of counts from different categories.\n",
    "  - For example, if our population has equal numbers of men and women, then we can test if our sample is different from those expected probabilities.\n",
    "\n",
    "The density of the $\\chi$-squared distribution depends on the degrees of freedom, k. The degrees of freedom is computed as k = number of possible outcomes - 1. The $\\chi$-squared distribution also depends on the value of the $\\chi$-squared statistic.\n",
    "\n",
    "\n",
    "<img src=\"img/Chi-square.png\" alt=\"Drawing\" style=\"width:500px; height:350px\"/>\n",
    "<center>Chi-square distribution for different degrees of freedom</center>\n",
    "\n",
    "As with any probability density function, confidence intervals and p-values can be computed. Notice that the $\\chi$-squared distribution becomes flatter and with greater dispersion as the degrees of freedom increase. In practice, this means that you will need large samples to get a meaningful result if you have too many choices in your test. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Karl Pearson\n",
    "\n",
    "Karl Pearson was the dean of late 19th and early 20th century mathematical statisticians. Pearson was a student of Frances Gaulton, the inventor of the regression method. Willam Sealy Gossett was one of Pearsons's students. This realationship is said to be the insparation for Gossett's pseudonym 'Student'. \n",
    "\n",
    "\n",
    "<img src=\"img/Karl_Pearson_1912.jpg\" alt=\"Drawing\" style=\"width:275x; height:350px\"/>\n",
    "<center>Karl Pearson in 1912: A scary looking statistics professor!</center>\n",
    "\n",
    "In many ways Pearson's influence on the mathematical foundations of statistics is still with us more than a century latter. Many of Pearson's methods are used on a daily basis. Most unfortunately, Pearson was also a eugenicist and a racist. His misuse of statistics in this area has tarnished his legacy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building a Chi-squared table\n",
    "\n",
    "The traditional way to apply a Chi-squared test is to first create a Chi-squared table. While such tables are not built piece by piece in modern practice, doing so will help you understand the principles involved.     \n",
    "\n",
    "In this example we are looking the results of an A-B test with three possible outcomes. For example, this type of test might be applied to determine if a new web site drives more customer purchases. \n",
    "\n",
    "the code in the cell below builds a simple Chi-squared table. The columns in the data frame are:\n",
    "\n",
    "- The actual occurrence of events.\n",
    "- The expected probability of these events. This is the **distribution of the null hypothesis**.\n",
    "- The expected occurrence of events given the expected probabilities under the null hypothesis.\n",
    "- The difference between the occurrence and the expected number of events under the null hypothesis.\n",
    "- The square of the difference.\n",
    "- The squared difference normalized by the expected number of occurrences. The sum of these figures in the Chi-squared statistic. \n",
    "\n",
    "Execute the code and examine the results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.stats.power as ssp\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ab_data = pd.DataFrame({'Action':['Leave Page', 'Continue Purchase', 'Add More to Purchase'],\n",
    "                       'occurrence':[55,43,22],\n",
    "                       'expected_per':[0.6,0.3,0.1]})\n",
    "sum_occurrence = ab_data.loc[:, 'occurrence'].sum()\n",
    "ab_data.loc[:, 'expected_occurance'] = sum_occurrence * ab_data.loc[:, 'expected_per']\n",
    "ab_data.loc[:, 'diff'] = ab_data.loc[:, 'occurrence'] - ab_data.loc[:, 'expected_occurance'] \n",
    "ab_data.loc[:, 'sqr_diff'] = ab_data.loc[:, 'diff'].apply(lambda x: x**2)\n",
    "ab_data.loc[:, 'diff_expect'] = ab_data.loc[:, 'sqr_diff'].div(ab_data.loc[:, 'expected_occurance'], axis='index')\n",
    "ab_data = ab_data.append({'Action': 'Totals',\n",
    "                      'occurrence': sum_occurrence,\n",
    "                       'expected_per':  [np.nan],\n",
    "                      'expected_occurance': [np.nan],\n",
    "                      'diff': [np.nan],\n",
    "                      'sqr_diff': [np.nan],\n",
    "                      'diff_expect': ab_data.loc[:, 'diff_expect'].sum()}, \n",
    "                        ignore_index =  True)\n",
    "ab_data = ab_data[['Action', 'occurrence', 'expected_per', 'expected_occurance', 'diff', 'sqr_diff', 'diff_expect']]\n",
    "ab_data                                       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Chi-squared table is interpreted as follows:\n",
    "\n",
    "- The $\\chi$-squared test statistic is 13.708, which is computed as the sum of the squared differences normalized by the expected occurrences.\n",
    "- The $\\chi$-squared distribution has (3 Outcomes - 1) = 2 degrees of freedom. Degree of freedom is the number of outcome options (3) minus 1.\n",
    "\n",
    "We need to compute the p-value given the $\\chi$-squared test statistic and the degrees of freedom. The [scipy.stata.chi2.cdf](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.chi2.html) method is used to compute the p-value. Execute the code in the cell below to compute the p-value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as ss\n",
    "1 - ss.chi2.cdf(13.7, df = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This p-value is rather small. Evidently, there is a small chance that the  differences between the occurrences and expected occurrences are from random variation alone. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing the Statistics\n",
    "\n",
    "In the foregoing example we computed the Chi-squared statistic and p-value directly. In general, this is a somewhat cumbersome approach. Instead, we can use the [scipy.stats.chisquare](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.chisquare.html) function to compute these statistics. Execute the code in the cell below and examine the results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chisq, pvalue = ss.chisquare(ab_data.loc[:, 'occurrence'][:3], \n",
    "             ab_data.loc[:, 'expected_occurance'][:3])\n",
    "print('Chi Squared statistic = ' + str(chisq))\n",
    "print('P=value = ' + str(pvalue))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The difference between the expected and observed number of occurrences is significant. The large Chi-squared value on 2 degrees of freedom and the small p-value indicate we can reject the null hypothesis that the observed occurrences follow the same distribution as the expected occurrences. There is a low chance that the sample arises from the null distribution. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Power of the test\n",
    "\n",
    "Finally, we should check the power of our test. Execute the code in the cell below and examine the results. In this case, we will use the [statsmodels.stats.power.GofChisquarePower().solve_power()](https://www.statsmodels.org/devel/generated/statsmodels.stats.power.GofChisquarePower.power.html#statsmodels.stats.power.GofChisquarePower.power) function to compute power vs. effect size. Execute this code to determine if this test has reasonable power."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_power(x, y, xlabel, title):\n",
    "    plt.plot(x, y, color = 'red', linewidth = 2)\n",
    "    plt.title(title)\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel('Power')\n",
    "\n",
    "diffs = np.arange(start = 0.1, stop = 1.0, step = 0.01) \n",
    "powers = ssp.GofChisquarePower().power(effect_size = diffs, nobs=120, n_bins = 3, alpha=0.05)\n",
    "plot_power(diffs, powers, xlabel = 'Difference', title = 'Power vs. difference') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apparently, this test is quite powerful, and we could have detected much smaller differences between the observed and expected counts. \n",
    "\n",
    "**Your Turn!** As you have observed, the test is quite powerful with 120 observations. But, what if we do not have a sample this large? Compute and plot the power of the Chi-squared test for an effect size of 1.0 at sample sizes in the range $\\{ 10, 100\\}$. The nobs argument specifies the sample size. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examine your results. At what sample size is the power of the test approximately 1.0? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fisher's Exact Test\n",
    "\n",
    "The assumptions behind the Chi-squared statistic breakdown when the sample size is small (e.g. number of occurrences $\\le 10$). In this case you can use Fisher's Exact Test. In practice Fisher's exact test is rarely used, but it is interesting  to think about it anyway as an example of a **permutation test**. \n",
    "\n",
    "According to the story, in 1911 Ronald Fisher worked in the same institution with a talented aquatic botanist, Dr. Muriel Bristol, who was quite particular about how her tea was served. Dr. Bristol told Fisher that she could tell the difference between cups of tea where the milk had been poured into the cup before or after the tea was poured. \n",
    "\n",
    "<img src=\"img/Bristol.png\" alt=\"Drawing\" style=\"width:450px; height:300px\"/>\n",
    "<center>Dr Muriel Bristol, noted aquatic botanist, and quite particular about her tea.\n",
    "\n",
    "Fisher, was a bit skeptical. He challenged Dr. Bristol to a test. In this test, Fisher prepared eight cups of tea. Four of the cups of where prepared in Dr. Bristol's preferred manner and the other four the other way. The tea was prepare out of sight of Dr. Bristol. However, she knew that there were four cups prepared each way. The order of presentation of each cup of tea was randomized. Fisher served the cups of tea to Dr. Bristol and asked her how the tea had been poured. In every case, she was correct!\n",
    "\n",
    "Fisher devised a **permutation test** to determine the likelihood that Dr Bristol could have simply guessed the correct outcome. He devised the following permutation table for the chances of success:\n",
    "\n",
    "<img src=\"img/tea.png\" alt=\"Drawing\" style=\"width:700px; height:300px\"/>\n",
    "\n",
    "The possible permutations of the ways that Dr Bristol could have correctly (success) or incorrectly (failure) identified the way each cup of tea was prepared is 8 choose 4:\n",
    "\n",
    "$$\\binom{8}{4} = \\frac{8!}{4!(8-4)!} = 70$$\n",
    "\n",
    "So, the chance that the Dr Bristol could purely guess (by random chance) the outcome is only 1 in 70 or about 1.4%. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example of Fisher's Exact Test\n",
    "\n",
    "As has already been stated, Fisher's exact test is a **small sample test**. Such tests are of limited importance in the 21st Century. There are still some cases where we must work with small samples. An example is with scientific data where collection of more data is expensive or simply infeasible.     \n",
    "\n",
    "Let's try an example of Fisher's exact test. Take a simple 2X2 matrix of counts. The counts are number of success and failures for two samples (two sets of Bernoulli trails), on the number of sharks and whales observed in two oceans over some period of time. The null distribution in this cases is that the proportion of sharks to whales is constant between the two oceans. This is a case where the observations are inherently limited and Fisher's exact test can be used.   \n",
    "\n",
    "The code in the cell below using the [scipy.stats.fisher_exact](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.fisher_exact.html) function to compute a Fisher exact test. Run the code and examine the results.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat_test = pd.DataFrame(np.array([[8,2],[1,5]]),\n",
    "                       index = ['wales', 'sharks'],\n",
    "                       columns = ['Atlantic', 'Indian'])\n",
    "print(mat_test)\n",
    "oddsratio, pvalue = ss.fisher_exact(mat_test)\n",
    "print('\\nOddsratio = ' + str(oddsratio))\n",
    "print('P-value = ' + str(pvalue))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "In this case, we can reject the null hypothesis. Evidently the difference of counts of wales and sharks in the two oceans from this experiment is unlikely to arise from the null distribution. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Summary\n",
    "\n",
    "We have covered lot of ground in this lesson. Specifically we have discussed:\n",
    "\n",
    "- The $\\chi$-squared test for count data. The null hypothesis is that there is no significant differences in the counts and the samples are from the same population. \n",
    "- Power of tests on counts. The power of a test is the probability of getting a positive result when the null hypothesis is not true. \n",
    "- Fisher's exact test is a permutation test suitable for small count samples. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Copyright 2019, 2020, Stephen F Elston. All rights reserved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
